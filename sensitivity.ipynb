{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"sensitivity.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNJ1J5RH3gtoHe5cha27jta"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"beycJY9qiQSl"},"outputs":[],"source":["!pip install interpret\n","!pip install kaleido\n","!pip install tabulate"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","from google.colab import files\n","working_directory = '/content/drive/My Drive/COS Seesaw Research'"],"metadata":{"id":"dG3exUGniz3S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import matplotlib.dates as mdates\n","import warnings\n","import shutil\n","from sklearn.model_selection import train_test_split\n","from interpret import show\n","from interpret import data\n","from tabulate import tabulate\n","from dateutil.relativedelta import relativedelta\n","from datetime import datetime as dt\n","\n","warnings.filterwarnings(\"ignore\")\n","\n"],"metadata":{"id":"CDB3LRIXi8tR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cos_sites = ['alt', 'brw', 'cgo', 'hfm', 'kum', 'lef', 'mhd', 'mlo', 'nwr', 'psa', 'smo', 'spo', 'sum', 'thd']\n","sensitivity_directory = working_directory + '/Sensitivity'\n","\n","\n","\n","base_path = sensitivity_directory + '/interval_correlation'\n","interval = relativedelta(months=1)\n","time_series_length = 5\n","short_list_length = 10\n","\n","#make required directory\n","if not os.path.isdir(base_path):\n","  os.mkdir(base_path)\n","else:\n","  shutil.rmtree(base_path)\n","  os.mkdir(base_path)\n","\n","for site in cos_sites:\n","  print(site)\n","  window_end = dt(year=2016, month=1, day=1)\n","  window_start = window_end + relativedelta(months=-2)\n","\n","  cos_target = 'COS_' + site\n","  df = pd.read_pickle(working_directory + '/Data/Pickles/correlation_pickles/' + site + '_dataframe.pkl')\n","  df = df.set_index('time')\n","\n","  save_path = base_path + '/' + site\n","  short_list_dict = {}\n","  short_list_time_dict = {}\n","\n","  if not os.path.isdir(save_path):\n","    os.mkdir(save_path)\n","  else:\n","    shutil.rmtree(save_path)\n","    os.mkdir(save_path)\n","\n","  for i in range(12):\n","    interval_df = df[window_start:window_end]\n","    print(window_start.date())\n","    print(window_end.date())\n","    \n","    columns = list(interval_df.columns)\n","    if cos_target in columns:\n","      columns.remove(cos_target)\n","    else:\n","      print('Error, target column not in dataframe')\n","      quit()\n","\n","    x = interval_df[columns]\n","    y = interval_df[cos_target]\n","\n","    marginal = data.Marginal()\n","    marginal_explanation = marginal.explain_data(x,y)\n","\n","    current_dict = {}\n","    fifteen_dict = {}\n","    month_dict = {}\n","    month_fifteen_dict = {}\n","    two_month_dict = {}\n","    index = 0\n","    all_dict = {}\n","    for variable in marginal_explanation.feature_names:\n","      val_to_append = marginal_explanation.data(key=index)['correlation']\n","\n","      if not variable in short_list_time_dict.keys():\n","        short_list_time_dict[variable] = []\n","      short_list_time_dict[variable].append(abs(val_to_append))\n","      \n","      \n","      all_dict[variable] = val_to_append\n","      temp = variable.split('-')\n","\n","      # build the short list entry\n","      if not temp[0] in short_list_dict.keys():\n","        short_list_dict[temp[0]] = []\n","      if abs(val_to_append) > 0.5:\n","        short_list_dict[temp[0]].append(abs(val_to_append))\n","      else:\n","        short_list_dict[temp[0]].append(0)\n","\n","      # abs correlation less than 0.5 means no correlation\n","      if not (abs(val_to_append) > 0.5):\n","        val_to_append = '-'\n","        \n","      if len(temp) == 1:\n","        current_dict[temp[0]] = val_to_append\n","      elif temp[1] == '15d':\n","        fifteen_dict[temp[0]] = val_to_append\n","      elif temp[1] == '1m':\n","        month_dict[temp[0]] = val_to_append\n","      elif temp[1] == '1m15d':\n","        month_fifteen_dict[temp[0]] = val_to_append\n","      elif temp[1] == '2m':\n","        two_month_dict[temp[0]] = val_to_append\n","      else:\n","        print(\"Error, what is this: \", temp[0], \", \", temp[1])\n","      index += 1\n","    columns = ['Time']\n","    #rows = ['Observation_time', '-15d', '-1m', '-1m15d', '-2m']\n","    current_row = ['current']\n","    fifteen_d_row = ['-15d']\n","    month_row = ['-1m']\n","    month_fifteen_row = ['-1m15d']\n","    two_month_row = ['-2m']\n","    for var in current_dict.keys():\n","      columns.append(var)\n","      current_row.append(current_dict[var])\n","      fifteen_d_row.append(fifteen_dict[var])\n","      month_row.append(month_dict[var])\n","      month_fifteen_row.append(month_fifteen_dict[var])\n","      two_month_row.append(two_month_dict[var])\n","    \n","    correlation_data = [current_row, fifteen_d_row, month_row, month_fifteen_row, two_month_row]\n","    save_table = tabulate(correlation_data, headers=columns, tablefmt='tsv')\n","    print(save_table)\n","    csv_path = save_path +'/' + site + '_correlation_' + str(window_end.date()) +'.csv'\n","    csv_file=open(csv_path, 'w')\n","    csv_file.write(save_table)\n","    csv_file.close()\n","\n","    window_end += interval\n","    window_start += interval\n","\n","  #calculate the short list\n","  for key in short_list_dict.keys():\n","    short_list_dict[key] = (sum(short_list_dict[key]) / len(short_list_dict[key]))\n","\n","  for key in short_list_time_dict.keys():\n","    short_list_time_dict[key] = (sum(short_list_time_dict[key]) / len(short_list_time_dict[key]))\n","\n","  short_list_time = []\n","  while len(short_list_time_dict.keys()) > 0:\n","    best = max(short_list_time_dict, key=short_list_time_dict.get)\n","    best_tuple = (best, short_list_time_dict.pop(best))\n","    short_list_time.append(best_tuple)\n","\n","  short_list = []\n","  while len(short_list_dict.keys()) > 0:\n","    best = max(short_list_dict, key=short_list_dict.get)\n","    best_tuple = (best, short_list_dict.pop(best))\n","    short_list.append(best_tuple)\n","  \n","  short_path = save_path + '/shortlist'\n","  if not os.path.isdir(short_path):\n","    os.mkdir(short_path)\n","  else:\n","    shutil.rmtree(short_path)\n","    os.mkdir(short_path)\n","\n","  short_list_path = short_path + '/' + site + '_short_list.txt'\n","  site_short_list = open(short_list_path, 'w')\n","\n","  i = 0\n","  for i in range(len(short_list)):\n","    if i == short_list_length:\n","      write_string = '\\n'\n","      site_short_list.write(write_string)\n","\n","    write_string = str(i + 1) + '. '+ str(short_list[i][0]) + ': '+ str(short_list[i][1]) + '\\n'\n","    site_short_list.write(write_string)\n","    i += 1\n","\n","  site_short_list.close()\n","\n","  short_list_path = short_path + '/' + site + '_short_list_time.txt'\n","  site_short_list = open(short_list_path, 'w')\n","\n","  i = 0\n","  for i in range(len(short_list_time)):\n","    if i == short_list_length:\n","      write_string = '\\n'\n","      site_short_list.write(write_string)\n","    \n","    write_string = str(i + 1) + '. '+ str(short_list_time[i][0]) + ': '+ str(short_list_time[i][1]) + '\\n'\n","    site_short_list.write(write_string)\n","    i += 1\n","\n","  site_short_list.close()\n","\n"],"metadata":{"id":"SR_cu7FOzDvS"},"execution_count":null,"outputs":[]}]}