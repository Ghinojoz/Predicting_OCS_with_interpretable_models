{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"add_ocs_to_feature_frame.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO92sK0UoD3M6imGRwkgSdr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"dHsQnkVwMgWg"},"outputs":[],"source":["!apt-get install -qq libgdal-dev libproj-dev\n","!pip install --no-binary shapely shapely --force\n","!pip install cartopy\n","!pip install regionmask"]},{"cell_type":"code","source":["#import required packages\n","import os\n","import warnings\n","import time\n","import regionmask\n","import gc\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import xarray as xr\n","import geopandas as gpd\n","import cartopy.crs as ccrs\n","import shapely\n","from datetime import datetime as dt\n","from shapely.geometry import Point\n","from shapely.geometry.polygon import Polygon\n","from scipy.interpolate import interp1d\n","from dateutil.relativedelta import relativedelta\n","from google.colab import drive\n","from google.colab import files"],"metadata":{"id":"_fGjRiyBMp2V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#establish working directory and mount drive\n","drive.mount('/content/drive')\n","working_directory = '/content/drive/My Drive/COS Seesaw Research'"],"metadata":{"id":"6KaSN7bEMshc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Parallel site arrays for constructing regions, and time delta for building feature time series in addition, contains the radius for defining map regions"],"metadata":{"id":"j4wC7gGNSuoO"}},{"cell_type":"code","source":["cos_sites = ['alt', 'brw', 'cgo', 'hfm', 'kum', 'lef', 'mhd', 'mlo', 'nwr', 'psa', 'smo', 'spo', 'sum', 'thd']\n","cos_site_centers = [(-62.3, 82.5), (-156.6, 71.3), (144.7,-40.7), (-72.2, 42.5), (-154.8, 19.5), (-90.3, 45.6), (-9.9, 53.3), (-155.6, 19.5), (-105.5, 40.1), (-64.0, -64.6), (-170.6, -14.2), (0, -90), (-38.4, 72.6), (-124.1,41.0)]\n","time_delta_general = [('-15d', relativedelta(days=-15)), ('-1m', relativedelta(months=-1)), ('-1m15d', relativedelta(months=-1, days=-15)), ('-2m', relativedelta(months=-2))]\n","region_size = 30\n","year_start = 2000\n","year_end = 2018\n","divider = ('-------------------------------------------------------------------------------------------------------')"],"metadata":{"id":"biTKC3leMvg8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Build regions"],"metadata":{"id":"ui5EmgycS2wW"}},{"cell_type":"code","source":["regions = None\n","names = []\n","abbrevs = []\n","region_list = []\n","\n","for i in range(len(cos_sites)):\n","  names.append(cos_sites[i])\n","  abbrevs.append(cos_sites[i])\n","  center_point = Point(cos_site_centers[i][0], cos_site_centers[i][1])\n","  circle = center_point.buffer(region_size)\n","\n","  #region_bound = np.array([list(cos_site_centers[i])])\n","  \n","  #region_list.append(region_bound)\n","  region_list.append(circle)\n","\n","#regions = regionmask.Regions(region_list, names=names, abbrevs=abbrevs, name='Ocean Regions')\n","regions = regionmask.Regions(region_list, names=names, abbrevs=abbrevs, name='Ocean Regions', overlap=True)\n","plt.figure(figsize=(24,12))\n","regions.plot(label='abbrev')\n","plt.show()"],"metadata":{"id":"wGK3bqFAzsmZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["site_frames = {}\n","file_name = working_directory + '/Data/OCS/OCS__GCMS_flask.txt'\n","time_column_name = 'yyyymmdd'\n","cos_data_full = pd.read_csv(file_name, delim_whitespace=True, header=1, parse_dates=[time_column_name])\n","for site in cos_sites:\n","  print('Initializing data frame for ', site)\n","  cos_data = cos_data_full.loc[cos_data_full['site'] == site]\n","  duplicates = cos_data.duplicated(keep=False, subset=[time_column_name])\n","  duplicate_entries = cos_data.where(duplicates)\n","  duplicate_entries.dropna(inplace=True)\n","  unique_dates = duplicate_entries[time_column_name].unique()\n","  same_day_avg = []\n","  for date in unique_dates:\n","    entry_subset = duplicate_entries.where(duplicate_entries[time_column_name] == date)\n","    entry_subset.dropna(inplace=True)\n","    ocs_col = entry_subset['OCS_']\n","    mean = ocs_col.mean()\n","    same_day_avg.append((date,mean))\n","  cos_data = cos_data.drop_duplicates(subset=[time_column_name])\n"," \n","  for avg in same_day_avg:\n","    cos_data.loc[cos_data[time_column_name] == avg[0], 'OCS_'] = avg[1]\n","  \n","  cos_data = cos_data[(cos_data[time_column_name] >= dt(year=year_start, month=1, day=1)) & (cos_data[time_column_name] < dt(year=year_end+1, month=1, day=1))]\n","  cos_column_name = 'COS_' + site\n","  cos_data = pd.DataFrame({'time':cos_data[time_column_name], cos_column_name : cos_data['OCS_'], 'OCS_stddev' : cos_data['OCS__sd']})\n","  cos_data = cos_data.reset_index(drop=True)\n","\n","  # add it to the dictionary\n","  #data_set = xr.Dataset({'time': xr.Variable(cos_data['time'])})\n","  site_frames[site] = cos_data.to_xarray()\n","  new_frame = site_frames[site].swap_dims({'index': 'time'})\n","  site_frames[site] = new_frame"],"metadata":{"id":"So5obmFY3egf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["interpolated_frames = {}\n","# build set of regular dates\n","days = pd.date_range(start=dt(year=2005, month=1, day=1), end=dt(year=2017, month=1, day=1), freq='SM')\n","print(days)\n","#date_frame = pd.DataFrame()\n","#date_frame['time'] =\n","date_frame = pd.DataFrame(data=days, columns=['time'])\n","print(date_frame)\n","for site in site_frames.keys():\n","  cos_name = 'COS_' + site\n","  print(site_frames[site])\n","  interp = site_frames[site][cos_name].interp(time=date_frame['time'], method='cubic')\n","  print(interp)\n","  interpolated_frames[site] = interp"],"metadata":{"id":"vkUQGBKu3wRn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for site in site_frames.keys():\n","  #cos_data = cos_data[(cos_data['time'] >= dt(year=year_start, month=1, day=1)) & (cos_data['time'] < dt(year=year_end+1, month=1, day=1))]\n","  print(site_frames[site])\n","  #print(interpolated_frames[site]['time'])\n","  #true_data = site_frames[site][(site_frames[site]['time'] >= dt(year=2005, month=1, day=1)) & (site_frames[site]['time'] < dt(year=2016, month=1, day=1))]\n","  #print(site_frames[site]['time'])\n","  fig, ax = plt.subplots(figsize=(12,6))\n","  ocs_name = 'COS_' + site\n","  ax.plot(site_frames[site]['time'], site_frames[site][ocs_name], label = 'True OCS')\n","  ax.plot(interpolated_frames[site]['time'], interpolated_frames[site], label = 'Interpolated OCS')\n","  plt.legend()\n","  plt.show()"],"metadata":{"id":"gsig_hpSBYQl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pickle_name = working_directory + '/Data/Pickles/correlation_frame.pkl'\n","feature_pickle = pd.read_pickle(pickle_name)\n","display(feature_pickle)"],"metadata":{"id":"srgW7ZULePXA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for site in interpolated_frames.keys():\n","  #print(interpolated_frames[site])\n","  #ocs_frame = interpolated_frames[site].to_dataframe()\n","  ocs_frame = interpolated_frames[site]\n","  working_df = feature_pickle.copy()\n","  cos_name = 'COS_' + site\n","  working_df[cos_name] = ocs_frame.data\n","  display(working_df)\n","  pickle_name = working_directory + '/Data/Pickles/correlation_pickles/' + site + '_dataframe.pkl'\n","  working_df.to_pickle(pickle_name)\n"],"metadata":{"id":"OCzGztLSkABS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["drive.flush_and_unmount()"],"metadata":{"id":"fdiOTw6nsrrQ"},"execution_count":null,"outputs":[]}]}